<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>declare4py.declare4py API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>declare4py.declare4py</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from .parsers import *
from .api_functions import *
import sys
import pm4py
import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import fpgrowth, apriori
from itertools import product


class Declare4Py:
    &#34;&#34;&#34;
    Wrapper that collects the input log and model, the output for the discovery, conformance checking and query
    checking tasks. In addition,

    Attributes
    ----------
    log : EventLog
        the input event log parsed from a XES file
    model : DeclModel
        the input DECLARE model parsed from a decl file
    log_length : int
        the trace number of the input log
    supported_templates : tuple[str]
        tuple containing all the DECLARE templates supported by the Declare4Py library
    binary_encoded_log : DataFrame
        the binary encoded version of the input log
    frequent_item_sets : DataFrame
        list of the most frequent item sets found along the log traces, together with their support and length
    conformance_checking_results : dict[tuple[int, str]: dict[str: CheckerResult]]
        output dictionary of the conformance_checking() function. Each entry contains:
        key = tuple[trace_pos_inside_log, trace_name]
        val = dict[ constraint_string : CheckerResult ]
    query_checking_results : dict[str: dict[str: str]]
        output dictionary of the query_checking() function. Each entry contains:
        key = constraint_string
        val = dict[ constraint_elem_key : constraint_elem_val ]
    discovery_results : dict[str: dict[tuple[int, str]: CheckerResult]]
        output dictionary of the discovery() function. Each entry contains:
        key = constraint_string
        val = dict[ tuple[trace_pos_inside_log, trace_name] : CheckerResult ]
    &#34;&#34;&#34;

    def __init__(self):
        self.log = None
        self.model = None
        self.log_length = None
        self.supported_templates = tuple(map(lambda c: c.templ_str, Template))
        self.binary_encoded_log = None
        self.frequent_item_sets = None
        self.conformance_checking_results = None
        self.query_checking_results = None
        self.discovery_results = None

    # LOG MANAGEMENT UTILITIES
    def parse_xes_log(self, log_path: str) -&gt; None:
        &#34;&#34;&#34;
        Set the &#39;log&#39; EventLog object and the &#39;log_length&#39; integer by reading and parsing the log corresponding to
        given log file path.

        Parameters
        ----------
        log_path : str
            File path where the log is stored.
        &#34;&#34;&#34;
        self.log = pm4py.read_xes(log_path)
        self.log_length = len(self.log)

    def activities_log_projection(self) -&gt; list[list[str]]:
        &#34;&#34;&#34;
        Return for each trace a time-ordered list of the activity names of the events.

        Returns
        -------
        projection
            nested lists, the outer one addresses traces while the inner one contains event activity names.
        &#34;&#34;&#34;
        projection = []
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        for trace in self.log:
            tmp_trace = []
            for event in trace:
                tmp_trace.append(event[&#34;concept:name&#34;])
            projection.append(tmp_trace)
        return projection

    def resources_log_projection(self) -&gt; list[list[str]]:
        &#34;&#34;&#34;
        Return for each trace a time-ordered list of the resources of the events.

        Returns
        -------
        projection
            nested lists, the outer one addresses traces while the inner one contains event activity names.
        &#34;&#34;&#34;
        projection = []
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        for trace in self.log:
            tmp_trace = []
            for event in trace:
                tmp_trace.append(event[&#34;org:group&#34;])
            projection.append(tmp_trace)
        return projection

    def log_encoding(self, dimension: str = &#39;act&#39;) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Return the log binary encoding, i.e. the one-hot encoding stating whether an attribute is contained
        or not inside each trace of the log.

        Parameters
        ----------
        dimension : str, optional
            choose &#39;act&#39; to perform the encoding over activity names, &#39;payload&#39; over resources (default &#39;act&#39;).

        Returns
        -------
        binary_encoded_log
            the one-hot encoding of the input log, made over activity names or resources depending on &#39;dimension&#39; value.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        te = TransactionEncoder()
        if dimension == &#39;act&#39;:
            dataset = self.activities_log_projection()
        elif dimension == &#39;payload&#39;:
            dataset = self.resources_log_projection()
        else:
            raise RuntimeError(f&#34;{dimension} dimension not supported. Choose between &#39;act&#39; and &#39;payload&#39;&#34;)
        te_ary = te.fit(dataset).transform(dataset)
        self.binary_encoded_log = pd.DataFrame(te_ary, columns=te.columns_)
        return self.binary_encoded_log

    def compute_frequent_itemsets(self, min_support: float, dimension: str = &#39;act&#39;, algorithm: str = &#39;fpgrowth&#39;,
                                  len_itemset: int = None) -&gt; None:
        &#34;&#34;&#34;
        Compute the most frequent item sets with a support greater or equal than &#39;min_support&#39; with the given algorithm
        and over the given dimension.

        Parameters
        ----------
        min_support: float
            the minimum support of the returned item sets.
        dimension : str, optional
            choose &#39;act&#39; to perform the encoding over activity names, &#39;payload&#39; over resources (default &#39;act&#39;).
        algorithm : str, optional
            the algorithm for extracting frequent itemsets, choose between &#39;fpgrowth&#39; (default) and &#39;apriori&#39;.
        len_itemset : int, optional
            the maximum length of the extracted itemsets.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        if not 0 &lt;= min_support &lt;= 1:
            raise RuntimeError(&#34;Min. support must be in range [0, 1].&#34;)

        self.log_encoding(dimension)
        if algorithm == &#39;fpgrowth&#39;:
            frequent_itemsets = fpgrowth(self.binary_encoded_log, min_support=min_support, use_colnames=True)
        elif algorithm == &#39;apriori&#39;:
            frequent_itemsets = apriori(self.binary_encoded_log, min_support=min_support, use_colnames=True)
        else:
            raise RuntimeError(f&#34;{algorithm} algorithm not supported. Choose between fpgrowth and apriori&#34;)
        frequent_itemsets[&#39;length&#39;] = frequent_itemsets[&#39;itemsets&#39;].apply(lambda x: len(x))
        if len_itemset is None:
            self.frequent_item_sets = frequent_itemsets
        else:
            self.frequent_item_sets = frequent_itemsets[(frequent_itemsets[&#39;length&#39;] &lt;= len_itemset)]

    def get_trace_keys(self) -&gt; list[tuple[int, str]]:
        &#34;&#34;&#34;
        Return the name of each trace, along with the position in the log.

        Returns
        -------
        trace_ids
            list containing the position in the log and the name of the trace.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        trace_ids = []
        for trace_id, trace in enumerate(self.log):
            trace_ids.append((trace_id, trace.attributes[&#34;concept:name&#34;]))
        return trace_ids

    def get_log_length(self) -&gt; int:
        &#34;&#34;&#34;
        Return the number of traces contained in the log.

        Returns
        -------
        log_length
            the length of the log.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        return self.log_length

    def get_log(self) -&gt; pm4py.objects.log.obj.EventLog:
        &#34;&#34;&#34;
        Return the log previously fed in input.

        Returns
        -------
        log
            the input log.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        return self.log

    def get_log_alphabet_payload(self) -&gt; set[str]:
        &#34;&#34;&#34;
        Return the set of resources that are in the log.

        Returns
        -------
        resources
            resource set.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        resources = set()
        for trace in self.log:
            for event in trace:
                resources.add(event[&#34;org:group&#34;])
        return resources

    def get_log_alphabet_activities(self):
        &#34;&#34;&#34;
        Return the set of activities that are in the log.

        Returns
        -------
        activities
            activity set.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        activities = set()
        for trace in self.log:
            for event in trace:
                activities.add(event[&#34;concept:name&#34;])
        return list(activities)

    def get_frequent_item_sets(self) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Return the set of extracted frequent item sets.

        Returns
        -------
        frequent_item_sets
            the set of extracted frequent item sets.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        if self.frequent_item_sets is None:
            raise RuntimeError(&#34;You must run the item set extraction algorithm before.&#34;)

        return self.frequent_item_sets

    def get_binary_encoded_log(self) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Return the one-hot encoding of the log.

        Returns
        -------
        binary_encoded_log
            the one-hot encoded log.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        if self.frequent_item_sets is None:
            raise RuntimeError(&#34;You must run the item set extraction algorithm before.&#34;)

        return self.binary_encoded_log

    # DECLARE UTILITIES
    def parse_decl_model(self, model_path) -&gt; None:
        &#34;&#34;&#34;
        Parse the input DECLARE model.

        Parameters
        ----------
        model_path : str
            File path where the DECLARE model is stored.
        &#34;&#34;&#34;
        self.model = parse_decl_from_file(model_path)

    def get_supported_templates(self) -&gt; tuple[str, ...]:
        &#34;&#34;&#34;
        Return the DECLARE templates supported by Declare4Py.

        Returns
        -------
        supported_templates
            tuple of names of the supported DECLARE templates.
        &#34;&#34;&#34;
        return self.supported_templates

    def get_model_activities(self) -&gt; list[str]:
        &#34;&#34;&#34;
        Return the activities contained in the DECLARE model.

        Returns
        -------
        activities
            list of activity names contained in the DECLARE model.
        &#34;&#34;&#34;
        if self.model is None:
            raise RuntimeError(&#34;You must load a DECLARE model before.&#34;)

        return self.model.activities

    def get_model_constraints(self) -&gt; list[str]:
        &#34;&#34;&#34;
        Return the constraints contained in the DECLARE model.

        Returns
        -------
        activities
            list of constraints contained in the DECLARE model.
        &#34;&#34;&#34;
        if self.model is None:
            raise RuntimeError(&#34;You must load a DECLARE model before.&#34;)

        return self.model.get_decl_model_constraints()

    # PROCESS MINING TASKS
    def conformance_checking(self, consider_vacuity: bool) -&gt; dict[tuple[int, str]: dict[str: CheckerResult]]:
        &#34;&#34;&#34;
        Performs conformance checking for the provided event log and DECLARE model.

        Parameters
        ----------
        consider_vacuity : bool
            True means that vacuously satisfied traces are considered as satisfied, violated otherwise.

        Returns
        -------
        conformance_checking_results
            dictionary where the key is a list containing trace position inside the log and the trace name, the value is
            a dictionary with keys the names of the constraints and values a CheckerResult object containing
            the number of pendings, activations, violations, fulfilments and the truth value of the trace for that
            constraint.
        &#34;&#34;&#34;
        print(&#34;Computing conformance checking ...&#34;)
        if self.log is None:
            raise RuntimeError(&#34;You must load the log before checking the model.&#34;)
        if self.model is None:
            raise RuntimeError(&#34;You must load the DECLARE model before checking the model.&#34;)

        self.conformance_checking_results = {}
        for i, trace in enumerate(self.log):
            trc_res = check_trace_conformance(trace, self.model, consider_vacuity)
            self.conformance_checking_results[(i, trace.attributes[&#34;concept:name&#34;])] = trc_res

        return self.conformance_checking_results

    def discovery(self, consider_vacuity: bool, max_declare_cardinality: int = 3, output_path: str = None) \
            -&gt; dict[str: dict[tuple[int, str]: CheckerResult]]:
        &#34;&#34;&#34;
        Performs discovery of the supported DECLARE templates for the provided log by using the computed frequent item
        sets.

        Parameters
        ----------
        consider_vacuity : bool
            True means that vacuously satisfied traces are considered as satisfied, violated otherwise.

        max_declare_cardinality : int, optional
            the maximum cardinality that the algorithm checks for DECLARE templates supporting it (default 3).

        output_path : str, optional
            if specified, save the discovered constraints in a DECLARE model to the provided path.

        Returns
        -------
        discovery_results
            dictionary containing the results indexed by discovered constraints. The value is a dictionary with keys
            the tuples containing id and name of traces that satisfy the constraint. The values of this inner dictionary
            is a CheckerResult object containing the number of pendings, activations, violations, fulfilments.
        &#34;&#34;&#34;
        print(&#34;Computing discovery ...&#34;)
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        if self.frequent_item_sets is None:
            raise RuntimeError(&#34;You must discover frequent itemsets before.&#34;)
        if max_declare_cardinality &lt;= 0:
            raise RuntimeError(&#34;Cardinality must be greater than 0.&#34;)

        self.discovery_results = {}

        for item_set in self.frequent_item_sets[&#39;itemsets&#39;]:
            length = len(item_set)

            if length == 1:
                for templ in Template.get_unary_templates():
                    constraint = {&#34;template&#34;: templ, &#34;attributes&#34;: &#39;, &#39;.join(item_set), &#34;condition&#34;: (&#34;&#34;, &#34;&#34;)}
                    if not templ.supports_cardinality:
                        self.discovery_results |= discover_constraint(self.log, constraint, consider_vacuity)
                    else:
                        for i in range(max_declare_cardinality):
                            constraint[&#39;n&#39;] = i+1
                            self.discovery_results |= discover_constraint(self.log, constraint, consider_vacuity)

            elif length == 2:
                for templ in Template.get_binary_templates():
                    constraint = {&#34;template&#34;: templ, &#34;attributes&#34;: &#39;, &#39;.join(item_set), &#34;condition&#34;: (&#34;&#34;, &#34;&#34;, &#34;&#34;)}
                    self.discovery_results |= discover_constraint(self.log, constraint, consider_vacuity)

                    constraint[&#39;attributes&#39;] = &#39;, &#39;.join(reversed(list(item_set)))
                    self.discovery_results |= discover_constraint(self.log, constraint, consider_vacuity)

        activities_decl_format = &#34;activity &#34; + &#34;\nactivity &#34;.join(self.get_log_alphabet_activities()) + &#34;\n&#34;
        if output_path is not None:
            with open(output_path, &#39;w&#39;) as f:
                f.write(activities_decl_format)
                f.write(&#39;\n&#39;.join(self.discovery_results.keys()))

        return self.discovery_results

    def filter_discovery(self, min_support: float = 0, output_path: str = None) \
            -&gt; dict[str: dict[tuple[int, str]: CheckerResult]]:
        &#34;&#34;&#34;
        Filters discovery results by means of minimum support.

        Parameters
        ----------
        min_support : float, optional
            the minimum support that a discovered constraint needs to have to be included in the filtered result.

        output_path : str, optional
            if specified, save the filtered constraints in a DECLARE model to the provided path.

        Returns
        -------
        result
            dictionary containing the results indexed by discovered constraints. The value is a dictionary with keys
            the tuples containing id and name of traces that satisfy the constraint. The values of this inner dictionary
            is a CheckerResult object containing the number of pendings, activations, violations, fulfilments.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        if self.discovery_results is None:
            raise RuntimeError(&#34;You must run a Discovery task before.&#34;)
        if not 0 &lt;= min_support &lt;= 1:
            raise RuntimeError(&#34;Min. support must be in range [0, 1].&#34;)

        result = {}

        for key, val in self.discovery_results.items():
            support = len(val) / len(self.log)
            if support &gt;= min_support:
                result[key] = support

        if output_path is not None:
            with open(output_path, &#39;w&#39;) as f:
                f.write(&#34;activity &#34; + &#34;\nactivity &#34;.join(self.get_log_alphabet_activities()) + &#34;\n&#34;)
                f.write(&#39;\n&#39;.join(result.keys()))

        return result

    def query_checking(self, consider_vacuity: bool,
                       template_str: str = None, max_declare_cardinality: int = 1,
                       activation: str = None, target: str = None,
                       act_cond: str = None, trg_cond: str = None, time_cond: str = None,
                       min_support: float = 1.0, return_first: bool = False) -&gt; dict[str: dict[str: str]]:
        &#34;&#34;&#34;
        Performs query checking for a (list of) template, activation activity and target activity. Optional
        activation, target and time conditions can be specified.

        Parameters
        ----------
        consider_vacuity : bool
            True means that vacuously satisfied traces are considered as satisfied, violated otherwise.

        template_str : str, optional
            if specified, the query checking is restricted on this DECLARE template. If not, the query checking is
            performed over the whole set of supported templates.

        max_declare_cardinality : int, optional
            the maximum cardinality that the algorithm checks for DECLARE templates supporting it (default 1).

        activation : str, optional
            if specified, the query checking is restricted on this activation activity. If not, the query checking
            considers in turn each activity of the log as activation.

        target : str, optional
            if specified, the query checking is restricted on this target activity. If not, the query checking
            considers in turn each activity of the log as target.

        act_cond : str, optional
            optional activation condition to evaluate. It has to be written by following the DECLARE standard format.

        trg_cond : str, optional
            optional target condition to evaluate. It has to be written by following the DECLARE standard format.

        time_cond : str, optional
            optional time condition to evaluate. It has to be written by following the DECLARE standard format.

        min_support : float, optional
            the minimum support that a constraint needs to have to be included in the result (default 1).

        return_first : bool, optional
            if True, the algorithm returns only the first queried constraint that is above the minimum support. If
            False, the algorithm returns all the constraints above the min. support (default False).

        Returns
        -------
        query_checking_results
            dictionary with keys the DECLARE constraints satisfying the assignments. The values are a structured
            representations of these constraints.
        &#34;&#34;&#34;
        print(&#34;Computing query checking ...&#34;)

        is_template_given = bool(template_str)
        is_activation_given = bool(activation)
        is_target_given = bool(target)
        if not act_cond:
            act_cond = &#34;&#34;
        if not trg_cond:
            trg_cond = &#34;&#34;
        if not time_cond:
            time_cond = &#34;&#34;

        if not is_template_given and not is_activation_given and not is_target_given:
            raise RuntimeError(&#34;You must set at least one parameter among (template, activation, target).&#34;)
        if is_template_given:
            template = Template.get_template_from_string(template_str)
            if template is None:
                raise RuntimeError(&#34;You must insert a supported DECLARE template.&#34;)
            if not template.is_binary and is_target_given:
                raise RuntimeError(&#34;You cannot specify a target activity for unary templates.&#34;)
        if not 0 &lt;= min_support &lt;= 1:
            raise RuntimeError(&#34;Min. support must be in range [0, 1].&#34;)
        if max_declare_cardinality &lt;= 0:
            raise RuntimeError(&#34;Cardinality must be greater than 0.&#34;)
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)

        templates_to_check = list()
        if is_template_given:
            templates_to_check.append(template_str)
        else:
            templates_to_check += list(map(lambda t: t.templ_str, Template.get_binary_templates()))
            if not is_target_given:
                for template in Template.get_unary_templates():
                    if template.supports_cardinality:
                        for card in range(max_declare_cardinality):
                            templates_to_check.append(template.templ_str + str(card+1))
                    else:
                        templates_to_check.append(template.templ_str)

        activations_to_check = self.get_log_alphabet_activities() if activation is None else [activation]
        targets_to_check = self.get_log_alphabet_activities() if target is None else [target]
        activity_combos = tuple(filter(lambda c: c[0] != c[1], product(activations_to_check, targets_to_check)))

        self.query_checking_results = {}

        for template_str in templates_to_check:
            template_str, cardinality = re.search(r&#39;(^.+?)(\d*$)&#39;, template_str).groups()
            template = Template.get_template_from_string(template_str)

            constraint = {&#34;template&#34;: template}
            if cardinality:
                constraint[&#39;n&#39;] = int(cardinality)

            if template.is_binary:
                constraint[&#39;condition&#39;] = (act_cond, trg_cond, time_cond)
                for couple in activity_combos:
                    constraint[&#39;attributes&#39;] = &#39;, &#39;.join(couple)

                    constraint_str = query_constraint(self.log, constraint, consider_vacuity, min_support)
                    if constraint_str:
                        res_value = {
                            &#34;template&#34;: template_str, &#34;activation&#34;: couple[0], &#34;target&#34;: couple[1],
                            &#34;act_cond&#34;: act_cond, &#34;trg_cond&#34;: trg_cond, &#34;time_cond&#34;: time_cond
                        }
                        self.query_checking_results[constraint_str] = res_value
                        if return_first:
                            return self.query_checking_results

            else:   # unary template
                constraint[&#39;condition&#39;] = (act_cond, time_cond)
                for activity in activations_to_check:
                    constraint[&#39;attributes&#39;] = activity

                    constraint_str = query_constraint(self.log, constraint, consider_vacuity, min_support)
                    if constraint_str:
                        res_value = {
                            &#34;template&#34;: template_str, &#34;activation&#34;: activity,
                            &#34;act_cond&#34;: act_cond, &#34;time_cond&#34;: time_cond
                        }
                        self.query_checking_results[constraint_str] = res_value
                        if return_first:
                            return self.query_checking_results

        return self.query_checking_results

    def filter_query_checking(self, queries) -&gt; list[list[str]]:
        &#34;&#34;&#34;
        Filter query checking.

        Parameters
        ----------
        queries : list[str]
            elements of the constraint that the user want to filter out from query checking result. Choose one (or more)
            elements among: &#39;template&#39;, &#39;activation&#39;, &#39;target&#39;.

        Returns
        -------
        assignments
            list containing an entry for each constraint of query checking result. Each entry of the list is a list
            itself, containing the queried constraint elements.
        &#34;&#34;&#34;
        if self.query_checking_results is None:
            raise RuntimeError(&#34;You must run a query checking task before.&#34;)
        if len(queries) == 0 or len(queries) &gt; 3:
            raise RuntimeError(&#34;The list of queries has to contain at least one query and three queries as maximum&#34;)
        assignments = []
        for constraint in self.query_checking_results.keys():
            tmp_answer = []
            for query in queries:
                try:
                    tmp_answer.append(self.query_checking_results[constraint][query])
                except KeyError:
                    print(f&#34;{query} is not a valid query. Valid queries are template, activation, target.&#34;)
                    sys.exit(1)
            assignments.append(tmp_answer)
        return assignments

    # FUNCTIONS FOR PRINTING RESULTS ##############
    def print_conformance_results(self):
        if self.conformance_checking_results is None:
            raise RuntimeError(&#34;You must run conformance checking before!&#34;)

        for key, value in self.conformance_checking_results.items():
            print(&#39;Trace ID: &#39; + str(key[0]) + &#39; - &#34;&#39; + key[1] + &#39;&#34;&#39;)
            for item in value.items():
                print(&#39;\t&#39; + item[1].state + &#39;\ton &#39; + item[0])
            print()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="declare4py.declare4py.Declare4Py"><code class="flex name class">
<span>class <span class="ident">Declare4Py</span></span>
</code></dt>
<dd>
<div class="desc"><p>Wrapper that collects the input log and model, the output for the discovery, conformance checking and query
checking tasks. In addition,</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>log</code></strong> :&ensp;<code>EventLog</code></dt>
<dd>the input event log parsed from a XES file</dd>
<dt><strong><code>model</code></strong> :&ensp;<code>DeclModel</code></dt>
<dd>the input DECLARE model parsed from a decl file</dd>
<dt><strong><code>log_length</code></strong> :&ensp;<code>int</code></dt>
<dd>the trace number of the input log</dd>
<dt><strong><code>supported_templates</code></strong> :&ensp;<code>tuple[str]</code></dt>
<dd>tuple containing all the DECLARE templates supported by the Declare4Py library</dd>
<dt><strong><code>binary_encoded_log</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>the binary encoded version of the input log</dd>
<dt><strong><code>frequent_item_sets</code></strong> :&ensp;<code>DataFrame</code></dt>
<dd>list of the most frequent item sets found along the log traces, together with their support and length</dd>
<dt><strong><code>conformance_checking_results</code></strong> :&ensp;<code>dict[tuple[int, str]: dict[str: CheckerResult]]</code></dt>
<dd>output dictionary of the conformance_checking() function. Each entry contains:
key = tuple[trace_pos_inside_log, trace_name]
val = dict[ constraint_string : CheckerResult ]</dd>
<dt><strong><code>query_checking_results</code></strong> :&ensp;<code>dict[str: dict[str: str]]</code></dt>
<dd>output dictionary of the query_checking() function. Each entry contains:
key = constraint_string
val = dict[ constraint_elem_key : constraint_elem_val ]</dd>
<dt><strong><code>discovery_results</code></strong> :&ensp;<code>dict[str: dict[tuple[int, str]: CheckerResult]]</code></dt>
<dd>output dictionary of the discovery() function. Each entry contains:
key = constraint_string
val = dict[ tuple[trace_pos_inside_log, trace_name] : CheckerResult ]</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Declare4Py:
    &#34;&#34;&#34;
    Wrapper that collects the input log and model, the output for the discovery, conformance checking and query
    checking tasks. In addition,

    Attributes
    ----------
    log : EventLog
        the input event log parsed from a XES file
    model : DeclModel
        the input DECLARE model parsed from a decl file
    log_length : int
        the trace number of the input log
    supported_templates : tuple[str]
        tuple containing all the DECLARE templates supported by the Declare4Py library
    binary_encoded_log : DataFrame
        the binary encoded version of the input log
    frequent_item_sets : DataFrame
        list of the most frequent item sets found along the log traces, together with their support and length
    conformance_checking_results : dict[tuple[int, str]: dict[str: CheckerResult]]
        output dictionary of the conformance_checking() function. Each entry contains:
        key = tuple[trace_pos_inside_log, trace_name]
        val = dict[ constraint_string : CheckerResult ]
    query_checking_results : dict[str: dict[str: str]]
        output dictionary of the query_checking() function. Each entry contains:
        key = constraint_string
        val = dict[ constraint_elem_key : constraint_elem_val ]
    discovery_results : dict[str: dict[tuple[int, str]: CheckerResult]]
        output dictionary of the discovery() function. Each entry contains:
        key = constraint_string
        val = dict[ tuple[trace_pos_inside_log, trace_name] : CheckerResult ]
    &#34;&#34;&#34;

    def __init__(self):
        self.log = None
        self.model = None
        self.log_length = None
        self.supported_templates = tuple(map(lambda c: c.templ_str, Template))
        self.binary_encoded_log = None
        self.frequent_item_sets = None
        self.conformance_checking_results = None
        self.query_checking_results = None
        self.discovery_results = None

    # LOG MANAGEMENT UTILITIES
    def parse_xes_log(self, log_path: str) -&gt; None:
        &#34;&#34;&#34;
        Set the &#39;log&#39; EventLog object and the &#39;log_length&#39; integer by reading and parsing the log corresponding to
        given log file path.

        Parameters
        ----------
        log_path : str
            File path where the log is stored.
        &#34;&#34;&#34;
        self.log = pm4py.read_xes(log_path)
        self.log_length = len(self.log)

    def activities_log_projection(self) -&gt; list[list[str]]:
        &#34;&#34;&#34;
        Return for each trace a time-ordered list of the activity names of the events.

        Returns
        -------
        projection
            nested lists, the outer one addresses traces while the inner one contains event activity names.
        &#34;&#34;&#34;
        projection = []
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        for trace in self.log:
            tmp_trace = []
            for event in trace:
                tmp_trace.append(event[&#34;concept:name&#34;])
            projection.append(tmp_trace)
        return projection

    def resources_log_projection(self) -&gt; list[list[str]]:
        &#34;&#34;&#34;
        Return for each trace a time-ordered list of the resources of the events.

        Returns
        -------
        projection
            nested lists, the outer one addresses traces while the inner one contains event activity names.
        &#34;&#34;&#34;
        projection = []
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        for trace in self.log:
            tmp_trace = []
            for event in trace:
                tmp_trace.append(event[&#34;org:group&#34;])
            projection.append(tmp_trace)
        return projection

    def log_encoding(self, dimension: str = &#39;act&#39;) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Return the log binary encoding, i.e. the one-hot encoding stating whether an attribute is contained
        or not inside each trace of the log.

        Parameters
        ----------
        dimension : str, optional
            choose &#39;act&#39; to perform the encoding over activity names, &#39;payload&#39; over resources (default &#39;act&#39;).

        Returns
        -------
        binary_encoded_log
            the one-hot encoding of the input log, made over activity names or resources depending on &#39;dimension&#39; value.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        te = TransactionEncoder()
        if dimension == &#39;act&#39;:
            dataset = self.activities_log_projection()
        elif dimension == &#39;payload&#39;:
            dataset = self.resources_log_projection()
        else:
            raise RuntimeError(f&#34;{dimension} dimension not supported. Choose between &#39;act&#39; and &#39;payload&#39;&#34;)
        te_ary = te.fit(dataset).transform(dataset)
        self.binary_encoded_log = pd.DataFrame(te_ary, columns=te.columns_)
        return self.binary_encoded_log

    def compute_frequent_itemsets(self, min_support: float, dimension: str = &#39;act&#39;, algorithm: str = &#39;fpgrowth&#39;,
                                  len_itemset: int = None) -&gt; None:
        &#34;&#34;&#34;
        Compute the most frequent item sets with a support greater or equal than &#39;min_support&#39; with the given algorithm
        and over the given dimension.

        Parameters
        ----------
        min_support: float
            the minimum support of the returned item sets.
        dimension : str, optional
            choose &#39;act&#39; to perform the encoding over activity names, &#39;payload&#39; over resources (default &#39;act&#39;).
        algorithm : str, optional
            the algorithm for extracting frequent itemsets, choose between &#39;fpgrowth&#39; (default) and &#39;apriori&#39;.
        len_itemset : int, optional
            the maximum length of the extracted itemsets.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        if not 0 &lt;= min_support &lt;= 1:
            raise RuntimeError(&#34;Min. support must be in range [0, 1].&#34;)

        self.log_encoding(dimension)
        if algorithm == &#39;fpgrowth&#39;:
            frequent_itemsets = fpgrowth(self.binary_encoded_log, min_support=min_support, use_colnames=True)
        elif algorithm == &#39;apriori&#39;:
            frequent_itemsets = apriori(self.binary_encoded_log, min_support=min_support, use_colnames=True)
        else:
            raise RuntimeError(f&#34;{algorithm} algorithm not supported. Choose between fpgrowth and apriori&#34;)
        frequent_itemsets[&#39;length&#39;] = frequent_itemsets[&#39;itemsets&#39;].apply(lambda x: len(x))
        if len_itemset is None:
            self.frequent_item_sets = frequent_itemsets
        else:
            self.frequent_item_sets = frequent_itemsets[(frequent_itemsets[&#39;length&#39;] &lt;= len_itemset)]

    def get_trace_keys(self) -&gt; list[tuple[int, str]]:
        &#34;&#34;&#34;
        Return the name of each trace, along with the position in the log.

        Returns
        -------
        trace_ids
            list containing the position in the log and the name of the trace.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        trace_ids = []
        for trace_id, trace in enumerate(self.log):
            trace_ids.append((trace_id, trace.attributes[&#34;concept:name&#34;]))
        return trace_ids

    def get_log_length(self) -&gt; int:
        &#34;&#34;&#34;
        Return the number of traces contained in the log.

        Returns
        -------
        log_length
            the length of the log.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        return self.log_length

    def get_log(self) -&gt; pm4py.objects.log.obj.EventLog:
        &#34;&#34;&#34;
        Return the log previously fed in input.

        Returns
        -------
        log
            the input log.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        return self.log

    def get_log_alphabet_payload(self) -&gt; set[str]:
        &#34;&#34;&#34;
        Return the set of resources that are in the log.

        Returns
        -------
        resources
            resource set.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        resources = set()
        for trace in self.log:
            for event in trace:
                resources.add(event[&#34;org:group&#34;])
        return resources

    def get_log_alphabet_activities(self):
        &#34;&#34;&#34;
        Return the set of activities that are in the log.

        Returns
        -------
        activities
            activity set.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        activities = set()
        for trace in self.log:
            for event in trace:
                activities.add(event[&#34;concept:name&#34;])
        return list(activities)

    def get_frequent_item_sets(self) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Return the set of extracted frequent item sets.

        Returns
        -------
        frequent_item_sets
            the set of extracted frequent item sets.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        if self.frequent_item_sets is None:
            raise RuntimeError(&#34;You must run the item set extraction algorithm before.&#34;)

        return self.frequent_item_sets

    def get_binary_encoded_log(self) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Return the one-hot encoding of the log.

        Returns
        -------
        binary_encoded_log
            the one-hot encoded log.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        if self.frequent_item_sets is None:
            raise RuntimeError(&#34;You must run the item set extraction algorithm before.&#34;)

        return self.binary_encoded_log

    # DECLARE UTILITIES
    def parse_decl_model(self, model_path) -&gt; None:
        &#34;&#34;&#34;
        Parse the input DECLARE model.

        Parameters
        ----------
        model_path : str
            File path where the DECLARE model is stored.
        &#34;&#34;&#34;
        self.model = parse_decl_from_file(model_path)

    def get_supported_templates(self) -&gt; tuple[str, ...]:
        &#34;&#34;&#34;
        Return the DECLARE templates supported by Declare4Py.

        Returns
        -------
        supported_templates
            tuple of names of the supported DECLARE templates.
        &#34;&#34;&#34;
        return self.supported_templates

    def get_model_activities(self) -&gt; list[str]:
        &#34;&#34;&#34;
        Return the activities contained in the DECLARE model.

        Returns
        -------
        activities
            list of activity names contained in the DECLARE model.
        &#34;&#34;&#34;
        if self.model is None:
            raise RuntimeError(&#34;You must load a DECLARE model before.&#34;)

        return self.model.activities

    def get_model_constraints(self) -&gt; list[str]:
        &#34;&#34;&#34;
        Return the constraints contained in the DECLARE model.

        Returns
        -------
        activities
            list of constraints contained in the DECLARE model.
        &#34;&#34;&#34;
        if self.model is None:
            raise RuntimeError(&#34;You must load a DECLARE model before.&#34;)

        return self.model.get_decl_model_constraints()

    # PROCESS MINING TASKS
    def conformance_checking(self, consider_vacuity: bool) -&gt; dict[tuple[int, str]: dict[str: CheckerResult]]:
        &#34;&#34;&#34;
        Performs conformance checking for the provided event log and DECLARE model.

        Parameters
        ----------
        consider_vacuity : bool
            True means that vacuously satisfied traces are considered as satisfied, violated otherwise.

        Returns
        -------
        conformance_checking_results
            dictionary where the key is a list containing trace position inside the log and the trace name, the value is
            a dictionary with keys the names of the constraints and values a CheckerResult object containing
            the number of pendings, activations, violations, fulfilments and the truth value of the trace for that
            constraint.
        &#34;&#34;&#34;
        print(&#34;Computing conformance checking ...&#34;)
        if self.log is None:
            raise RuntimeError(&#34;You must load the log before checking the model.&#34;)
        if self.model is None:
            raise RuntimeError(&#34;You must load the DECLARE model before checking the model.&#34;)

        self.conformance_checking_results = {}
        for i, trace in enumerate(self.log):
            trc_res = check_trace_conformance(trace, self.model, consider_vacuity)
            self.conformance_checking_results[(i, trace.attributes[&#34;concept:name&#34;])] = trc_res

        return self.conformance_checking_results

    def discovery(self, consider_vacuity: bool, max_declare_cardinality: int = 3, output_path: str = None) \
            -&gt; dict[str: dict[tuple[int, str]: CheckerResult]]:
        &#34;&#34;&#34;
        Performs discovery of the supported DECLARE templates for the provided log by using the computed frequent item
        sets.

        Parameters
        ----------
        consider_vacuity : bool
            True means that vacuously satisfied traces are considered as satisfied, violated otherwise.

        max_declare_cardinality : int, optional
            the maximum cardinality that the algorithm checks for DECLARE templates supporting it (default 3).

        output_path : str, optional
            if specified, save the discovered constraints in a DECLARE model to the provided path.

        Returns
        -------
        discovery_results
            dictionary containing the results indexed by discovered constraints. The value is a dictionary with keys
            the tuples containing id and name of traces that satisfy the constraint. The values of this inner dictionary
            is a CheckerResult object containing the number of pendings, activations, violations, fulfilments.
        &#34;&#34;&#34;
        print(&#34;Computing discovery ...&#34;)
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        if self.frequent_item_sets is None:
            raise RuntimeError(&#34;You must discover frequent itemsets before.&#34;)
        if max_declare_cardinality &lt;= 0:
            raise RuntimeError(&#34;Cardinality must be greater than 0.&#34;)

        self.discovery_results = {}

        for item_set in self.frequent_item_sets[&#39;itemsets&#39;]:
            length = len(item_set)

            if length == 1:
                for templ in Template.get_unary_templates():
                    constraint = {&#34;template&#34;: templ, &#34;attributes&#34;: &#39;, &#39;.join(item_set), &#34;condition&#34;: (&#34;&#34;, &#34;&#34;)}
                    if not templ.supports_cardinality:
                        self.discovery_results |= discover_constraint(self.log, constraint, consider_vacuity)
                    else:
                        for i in range(max_declare_cardinality):
                            constraint[&#39;n&#39;] = i+1
                            self.discovery_results |= discover_constraint(self.log, constraint, consider_vacuity)

            elif length == 2:
                for templ in Template.get_binary_templates():
                    constraint = {&#34;template&#34;: templ, &#34;attributes&#34;: &#39;, &#39;.join(item_set), &#34;condition&#34;: (&#34;&#34;, &#34;&#34;, &#34;&#34;)}
                    self.discovery_results |= discover_constraint(self.log, constraint, consider_vacuity)

                    constraint[&#39;attributes&#39;] = &#39;, &#39;.join(reversed(list(item_set)))
                    self.discovery_results |= discover_constraint(self.log, constraint, consider_vacuity)

        activities_decl_format = &#34;activity &#34; + &#34;\nactivity &#34;.join(self.get_log_alphabet_activities()) + &#34;\n&#34;
        if output_path is not None:
            with open(output_path, &#39;w&#39;) as f:
                f.write(activities_decl_format)
                f.write(&#39;\n&#39;.join(self.discovery_results.keys()))

        return self.discovery_results

    def filter_discovery(self, min_support: float = 0, output_path: str = None) \
            -&gt; dict[str: dict[tuple[int, str]: CheckerResult]]:
        &#34;&#34;&#34;
        Filters discovery results by means of minimum support.

        Parameters
        ----------
        min_support : float, optional
            the minimum support that a discovered constraint needs to have to be included in the filtered result.

        output_path : str, optional
            if specified, save the filtered constraints in a DECLARE model to the provided path.

        Returns
        -------
        result
            dictionary containing the results indexed by discovered constraints. The value is a dictionary with keys
            the tuples containing id and name of traces that satisfy the constraint. The values of this inner dictionary
            is a CheckerResult object containing the number of pendings, activations, violations, fulfilments.
        &#34;&#34;&#34;
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)
        if self.discovery_results is None:
            raise RuntimeError(&#34;You must run a Discovery task before.&#34;)
        if not 0 &lt;= min_support &lt;= 1:
            raise RuntimeError(&#34;Min. support must be in range [0, 1].&#34;)

        result = {}

        for key, val in self.discovery_results.items():
            support = len(val) / len(self.log)
            if support &gt;= min_support:
                result[key] = support

        if output_path is not None:
            with open(output_path, &#39;w&#39;) as f:
                f.write(&#34;activity &#34; + &#34;\nactivity &#34;.join(self.get_log_alphabet_activities()) + &#34;\n&#34;)
                f.write(&#39;\n&#39;.join(result.keys()))

        return result

    def query_checking(self, consider_vacuity: bool,
                       template_str: str = None, max_declare_cardinality: int = 1,
                       activation: str = None, target: str = None,
                       act_cond: str = None, trg_cond: str = None, time_cond: str = None,
                       min_support: float = 1.0, return_first: bool = False) -&gt; dict[str: dict[str: str]]:
        &#34;&#34;&#34;
        Performs query checking for a (list of) template, activation activity and target activity. Optional
        activation, target and time conditions can be specified.

        Parameters
        ----------
        consider_vacuity : bool
            True means that vacuously satisfied traces are considered as satisfied, violated otherwise.

        template_str : str, optional
            if specified, the query checking is restricted on this DECLARE template. If not, the query checking is
            performed over the whole set of supported templates.

        max_declare_cardinality : int, optional
            the maximum cardinality that the algorithm checks for DECLARE templates supporting it (default 1).

        activation : str, optional
            if specified, the query checking is restricted on this activation activity. If not, the query checking
            considers in turn each activity of the log as activation.

        target : str, optional
            if specified, the query checking is restricted on this target activity. If not, the query checking
            considers in turn each activity of the log as target.

        act_cond : str, optional
            optional activation condition to evaluate. It has to be written by following the DECLARE standard format.

        trg_cond : str, optional
            optional target condition to evaluate. It has to be written by following the DECLARE standard format.

        time_cond : str, optional
            optional time condition to evaluate. It has to be written by following the DECLARE standard format.

        min_support : float, optional
            the minimum support that a constraint needs to have to be included in the result (default 1).

        return_first : bool, optional
            if True, the algorithm returns only the first queried constraint that is above the minimum support. If
            False, the algorithm returns all the constraints above the min. support (default False).

        Returns
        -------
        query_checking_results
            dictionary with keys the DECLARE constraints satisfying the assignments. The values are a structured
            representations of these constraints.
        &#34;&#34;&#34;
        print(&#34;Computing query checking ...&#34;)

        is_template_given = bool(template_str)
        is_activation_given = bool(activation)
        is_target_given = bool(target)
        if not act_cond:
            act_cond = &#34;&#34;
        if not trg_cond:
            trg_cond = &#34;&#34;
        if not time_cond:
            time_cond = &#34;&#34;

        if not is_template_given and not is_activation_given and not is_target_given:
            raise RuntimeError(&#34;You must set at least one parameter among (template, activation, target).&#34;)
        if is_template_given:
            template = Template.get_template_from_string(template_str)
            if template is None:
                raise RuntimeError(&#34;You must insert a supported DECLARE template.&#34;)
            if not template.is_binary and is_target_given:
                raise RuntimeError(&#34;You cannot specify a target activity for unary templates.&#34;)
        if not 0 &lt;= min_support &lt;= 1:
            raise RuntimeError(&#34;Min. support must be in range [0, 1].&#34;)
        if max_declare_cardinality &lt;= 0:
            raise RuntimeError(&#34;Cardinality must be greater than 0.&#34;)
        if self.log is None:
            raise RuntimeError(&#34;You must load a log before.&#34;)

        templates_to_check = list()
        if is_template_given:
            templates_to_check.append(template_str)
        else:
            templates_to_check += list(map(lambda t: t.templ_str, Template.get_binary_templates()))
            if not is_target_given:
                for template in Template.get_unary_templates():
                    if template.supports_cardinality:
                        for card in range(max_declare_cardinality):
                            templates_to_check.append(template.templ_str + str(card+1))
                    else:
                        templates_to_check.append(template.templ_str)

        activations_to_check = self.get_log_alphabet_activities() if activation is None else [activation]
        targets_to_check = self.get_log_alphabet_activities() if target is None else [target]
        activity_combos = tuple(filter(lambda c: c[0] != c[1], product(activations_to_check, targets_to_check)))

        self.query_checking_results = {}

        for template_str in templates_to_check:
            template_str, cardinality = re.search(r&#39;(^.+?)(\d*$)&#39;, template_str).groups()
            template = Template.get_template_from_string(template_str)

            constraint = {&#34;template&#34;: template}
            if cardinality:
                constraint[&#39;n&#39;] = int(cardinality)

            if template.is_binary:
                constraint[&#39;condition&#39;] = (act_cond, trg_cond, time_cond)
                for couple in activity_combos:
                    constraint[&#39;attributes&#39;] = &#39;, &#39;.join(couple)

                    constraint_str = query_constraint(self.log, constraint, consider_vacuity, min_support)
                    if constraint_str:
                        res_value = {
                            &#34;template&#34;: template_str, &#34;activation&#34;: couple[0], &#34;target&#34;: couple[1],
                            &#34;act_cond&#34;: act_cond, &#34;trg_cond&#34;: trg_cond, &#34;time_cond&#34;: time_cond
                        }
                        self.query_checking_results[constraint_str] = res_value
                        if return_first:
                            return self.query_checking_results

            else:   # unary template
                constraint[&#39;condition&#39;] = (act_cond, time_cond)
                for activity in activations_to_check:
                    constraint[&#39;attributes&#39;] = activity

                    constraint_str = query_constraint(self.log, constraint, consider_vacuity, min_support)
                    if constraint_str:
                        res_value = {
                            &#34;template&#34;: template_str, &#34;activation&#34;: activity,
                            &#34;act_cond&#34;: act_cond, &#34;time_cond&#34;: time_cond
                        }
                        self.query_checking_results[constraint_str] = res_value
                        if return_first:
                            return self.query_checking_results

        return self.query_checking_results

    def filter_query_checking(self, queries) -&gt; list[list[str]]:
        &#34;&#34;&#34;
        Filter query checking.

        Parameters
        ----------
        queries : list[str]
            elements of the constraint that the user want to filter out from query checking result. Choose one (or more)
            elements among: &#39;template&#39;, &#39;activation&#39;, &#39;target&#39;.

        Returns
        -------
        assignments
            list containing an entry for each constraint of query checking result. Each entry of the list is a list
            itself, containing the queried constraint elements.
        &#34;&#34;&#34;
        if self.query_checking_results is None:
            raise RuntimeError(&#34;You must run a query checking task before.&#34;)
        if len(queries) == 0 or len(queries) &gt; 3:
            raise RuntimeError(&#34;The list of queries has to contain at least one query and three queries as maximum&#34;)
        assignments = []
        for constraint in self.query_checking_results.keys():
            tmp_answer = []
            for query in queries:
                try:
                    tmp_answer.append(self.query_checking_results[constraint][query])
                except KeyError:
                    print(f&#34;{query} is not a valid query. Valid queries are template, activation, target.&#34;)
                    sys.exit(1)
            assignments.append(tmp_answer)
        return assignments

    # FUNCTIONS FOR PRINTING RESULTS ##############
    def print_conformance_results(self):
        if self.conformance_checking_results is None:
            raise RuntimeError(&#34;You must run conformance checking before!&#34;)

        for key, value in self.conformance_checking_results.items():
            print(&#39;Trace ID: &#39; + str(key[0]) + &#39; - &#34;&#39; + key[1] + &#39;&#34;&#39;)
            for item in value.items():
                print(&#39;\t&#39; + item[1].state + &#39;\ton &#39; + item[0])
            print()</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="declare4py.declare4py.Declare4Py.activities_log_projection"><code class="name flex">
<span>def <span class="ident">activities_log_projection</span></span>(<span>self) >list</span>
</code></dt>
<dd>
<div class="desc"><p>Return for each trace a time-ordered list of the activity names of the events.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>projection</code></dt>
<dd>nested lists, the outer one addresses traces while the inner one contains event activity names.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def activities_log_projection(self) -&gt; list[list[str]]:
    &#34;&#34;&#34;
    Return for each trace a time-ordered list of the activity names of the events.

    Returns
    -------
    projection
        nested lists, the outer one addresses traces while the inner one contains event activity names.
    &#34;&#34;&#34;
    projection = []
    if self.log is None:
        raise RuntimeError(&#34;You must load a log before.&#34;)
    for trace in self.log:
        tmp_trace = []
        for event in trace:
            tmp_trace.append(event[&#34;concept:name&#34;])
        projection.append(tmp_trace)
    return projection</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.compute_frequent_itemsets"><code class="name flex">
<span>def <span class="ident">compute_frequent_itemsets</span></span>(<span>self, min_support:float, dimension:str='act', algorithm:str='fpgrowth', len_itemset:int=None) >None</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the most frequent item sets with a support greater or equal than 'min_support' with the given algorithm
and over the given dimension.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>min_support</code></strong> :&ensp;<code>float</code></dt>
<dd>the minimum support of the returned item sets.</dd>
<dt><strong><code>dimension</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>choose 'act' to perform the encoding over activity names, 'payload' over resources (default 'act').</dd>
<dt><strong><code>algorithm</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>the algorithm for extracting frequent itemsets, choose between 'fpgrowth' (default) and 'apriori'.</dd>
<dt><strong><code>len_itemset</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>the maximum length of the extracted itemsets.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_frequent_itemsets(self, min_support: float, dimension: str = &#39;act&#39;, algorithm: str = &#39;fpgrowth&#39;,
                              len_itemset: int = None) -&gt; None:
    &#34;&#34;&#34;
    Compute the most frequent item sets with a support greater or equal than &#39;min_support&#39; with the given algorithm
    and over the given dimension.

    Parameters
    ----------
    min_support: float
        the minimum support of the returned item sets.
    dimension : str, optional
        choose &#39;act&#39; to perform the encoding over activity names, &#39;payload&#39; over resources (default &#39;act&#39;).
    algorithm : str, optional
        the algorithm for extracting frequent itemsets, choose between &#39;fpgrowth&#39; (default) and &#39;apriori&#39;.
    len_itemset : int, optional
        the maximum length of the extracted itemsets.
    &#34;&#34;&#34;
    if self.log is None:
        raise RuntimeError(&#34;You must load a log before.&#34;)
    if not 0 &lt;= min_support &lt;= 1:
        raise RuntimeError(&#34;Min. support must be in range [0, 1].&#34;)

    self.log_encoding(dimension)
    if algorithm == &#39;fpgrowth&#39;:
        frequent_itemsets = fpgrowth(self.binary_encoded_log, min_support=min_support, use_colnames=True)
    elif algorithm == &#39;apriori&#39;:
        frequent_itemsets = apriori(self.binary_encoded_log, min_support=min_support, use_colnames=True)
    else:
        raise RuntimeError(f&#34;{algorithm} algorithm not supported. Choose between fpgrowth and apriori&#34;)
    frequent_itemsets[&#39;length&#39;] = frequent_itemsets[&#39;itemsets&#39;].apply(lambda x: len(x))
    if len_itemset is None:
        self.frequent_item_sets = frequent_itemsets
    else:
        self.frequent_item_sets = frequent_itemsets[(frequent_itemsets[&#39;length&#39;] &lt;= len_itemset)]</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.conformance_checking"><code class="name flex">
<span>def <span class="ident">conformance_checking</span></span>(<span>self, consider_vacuity:bool) >dict</span>
</code></dt>
<dd>
<div class="desc"><p>Performs conformance checking for the provided event log and DECLARE model.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>consider_vacuity</code></strong> :&ensp;<code>bool</code></dt>
<dd>True means that vacuously satisfied traces are considered as satisfied, violated otherwise.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>conformance_checking_results</code></dt>
<dd>dictionary where the key is a list containing trace position inside the log and the trace name, the value is
a dictionary with keys the names of the constraints and values a CheckerResult object containing
the number of pendings, activations, violations, fulfilments and the truth value of the trace for that
constraint.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def conformance_checking(self, consider_vacuity: bool) -&gt; dict[tuple[int, str]: dict[str: CheckerResult]]:
    &#34;&#34;&#34;
    Performs conformance checking for the provided event log and DECLARE model.

    Parameters
    ----------
    consider_vacuity : bool
        True means that vacuously satisfied traces are considered as satisfied, violated otherwise.

    Returns
    -------
    conformance_checking_results
        dictionary where the key is a list containing trace position inside the log and the trace name, the value is
        a dictionary with keys the names of the constraints and values a CheckerResult object containing
        the number of pendings, activations, violations, fulfilments and the truth value of the trace for that
        constraint.
    &#34;&#34;&#34;
    print(&#34;Computing conformance checking ...&#34;)
    if self.log is None:
        raise RuntimeError(&#34;You must load the log before checking the model.&#34;)
    if self.model is None:
        raise RuntimeError(&#34;You must load the DECLARE model before checking the model.&#34;)

    self.conformance_checking_results = {}
    for i, trace in enumerate(self.log):
        trc_res = check_trace_conformance(trace, self.model, consider_vacuity)
        self.conformance_checking_results[(i, trace.attributes[&#34;concept:name&#34;])] = trc_res

    return self.conformance_checking_results</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.discovery"><code class="name flex">
<span>def <span class="ident">discovery</span></span>(<span>self, consider_vacuity:bool, max_declare_cardinality:int=3, output_path:str=None) >dict</span>
</code></dt>
<dd>
<div class="desc"><p>Performs discovery of the supported DECLARE templates for the provided log by using the computed frequent item
sets.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>consider_vacuity</code></strong> :&ensp;<code>bool</code></dt>
<dd>True means that vacuously satisfied traces are considered as satisfied, violated otherwise.</dd>
<dt><strong><code>max_declare_cardinality</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>the maximum cardinality that the algorithm checks for DECLARE templates supporting it (default 3).</dd>
<dt><strong><code>output_path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>if specified, save the discovered constraints in a DECLARE model to the provided path.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>discovery_results</code></dt>
<dd>dictionary containing the results indexed by discovered constraints. The value is a dictionary with keys
the tuples containing id and name of traces that satisfy the constraint. The values of this inner dictionary
is a CheckerResult object containing the number of pendings, activations, violations, fulfilments.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def discovery(self, consider_vacuity: bool, max_declare_cardinality: int = 3, output_path: str = None) \
        -&gt; dict[str: dict[tuple[int, str]: CheckerResult]]:
    &#34;&#34;&#34;
    Performs discovery of the supported DECLARE templates for the provided log by using the computed frequent item
    sets.

    Parameters
    ----------
    consider_vacuity : bool
        True means that vacuously satisfied traces are considered as satisfied, violated otherwise.

    max_declare_cardinality : int, optional
        the maximum cardinality that the algorithm checks for DECLARE templates supporting it (default 3).

    output_path : str, optional
        if specified, save the discovered constraints in a DECLARE model to the provided path.

    Returns
    -------
    discovery_results
        dictionary containing the results indexed by discovered constraints. The value is a dictionary with keys
        the tuples containing id and name of traces that satisfy the constraint. The values of this inner dictionary
        is a CheckerResult object containing the number of pendings, activations, violations, fulfilments.
    &#34;&#34;&#34;
    print(&#34;Computing discovery ...&#34;)
    if self.log is None:
        raise RuntimeError(&#34;You must load a log before.&#34;)
    if self.frequent_item_sets is None:
        raise RuntimeError(&#34;You must discover frequent itemsets before.&#34;)
    if max_declare_cardinality &lt;= 0:
        raise RuntimeError(&#34;Cardinality must be greater than 0.&#34;)

    self.discovery_results = {}

    for item_set in self.frequent_item_sets[&#39;itemsets&#39;]:
        length = len(item_set)

        if length == 1:
            for templ in Template.get_unary_templates():
                constraint = {&#34;template&#34;: templ, &#34;attributes&#34;: &#39;, &#39;.join(item_set), &#34;condition&#34;: (&#34;&#34;, &#34;&#34;)}
                if not templ.supports_cardinality:
                    self.discovery_results |= discover_constraint(self.log, constraint, consider_vacuity)
                else:
                    for i in range(max_declare_cardinality):
                        constraint[&#39;n&#39;] = i+1
                        self.discovery_results |= discover_constraint(self.log, constraint, consider_vacuity)

        elif length == 2:
            for templ in Template.get_binary_templates():
                constraint = {&#34;template&#34;: templ, &#34;attributes&#34;: &#39;, &#39;.join(item_set), &#34;condition&#34;: (&#34;&#34;, &#34;&#34;, &#34;&#34;)}
                self.discovery_results |= discover_constraint(self.log, constraint, consider_vacuity)

                constraint[&#39;attributes&#39;] = &#39;, &#39;.join(reversed(list(item_set)))
                self.discovery_results |= discover_constraint(self.log, constraint, consider_vacuity)

    activities_decl_format = &#34;activity &#34; + &#34;\nactivity &#34;.join(self.get_log_alphabet_activities()) + &#34;\n&#34;
    if output_path is not None:
        with open(output_path, &#39;w&#39;) as f:
            f.write(activities_decl_format)
            f.write(&#39;\n&#39;.join(self.discovery_results.keys()))

    return self.discovery_results</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.filter_discovery"><code class="name flex">
<span>def <span class="ident">filter_discovery</span></span>(<span>self, min_support:float=0, output_path:str=None) >dict</span>
</code></dt>
<dd>
<div class="desc"><p>Filters discovery results by means of minimum support.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>min_support</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>the minimum support that a discovered constraint needs to have to be included in the filtered result.</dd>
<dt><strong><code>output_path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>if specified, save the filtered constraints in a DECLARE model to the provided path.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>result</code></dt>
<dd>dictionary containing the results indexed by discovered constraints. The value is a dictionary with keys
the tuples containing id and name of traces that satisfy the constraint. The values of this inner dictionary
is a CheckerResult object containing the number of pendings, activations, violations, fulfilments.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filter_discovery(self, min_support: float = 0, output_path: str = None) \
        -&gt; dict[str: dict[tuple[int, str]: CheckerResult]]:
    &#34;&#34;&#34;
    Filters discovery results by means of minimum support.

    Parameters
    ----------
    min_support : float, optional
        the minimum support that a discovered constraint needs to have to be included in the filtered result.

    output_path : str, optional
        if specified, save the filtered constraints in a DECLARE model to the provided path.

    Returns
    -------
    result
        dictionary containing the results indexed by discovered constraints. The value is a dictionary with keys
        the tuples containing id and name of traces that satisfy the constraint. The values of this inner dictionary
        is a CheckerResult object containing the number of pendings, activations, violations, fulfilments.
    &#34;&#34;&#34;
    if self.log is None:
        raise RuntimeError(&#34;You must load a log before.&#34;)
    if self.discovery_results is None:
        raise RuntimeError(&#34;You must run a Discovery task before.&#34;)
    if not 0 &lt;= min_support &lt;= 1:
        raise RuntimeError(&#34;Min. support must be in range [0, 1].&#34;)

    result = {}

    for key, val in self.discovery_results.items():
        support = len(val) / len(self.log)
        if support &gt;= min_support:
            result[key] = support

    if output_path is not None:
        with open(output_path, &#39;w&#39;) as f:
            f.write(&#34;activity &#34; + &#34;\nactivity &#34;.join(self.get_log_alphabet_activities()) + &#34;\n&#34;)
            f.write(&#39;\n&#39;.join(result.keys()))

    return result</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.filter_query_checking"><code class="name flex">
<span>def <span class="ident">filter_query_checking</span></span>(<span>self, queries) >list</span>
</code></dt>
<dd>
<div class="desc"><p>Filter query checking.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>queries</code></strong> :&ensp;<code>list[str]</code></dt>
<dd>elements of the constraint that the user want to filter out from query checking result. Choose one (or more)
elements among: 'template', 'activation', 'target'.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>assignments</code></dt>
<dd>list containing an entry for each constraint of query checking result. Each entry of the list is a list
itself, containing the queried constraint elements.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filter_query_checking(self, queries) -&gt; list[list[str]]:
    &#34;&#34;&#34;
    Filter query checking.

    Parameters
    ----------
    queries : list[str]
        elements of the constraint that the user want to filter out from query checking result. Choose one (or more)
        elements among: &#39;template&#39;, &#39;activation&#39;, &#39;target&#39;.

    Returns
    -------
    assignments
        list containing an entry for each constraint of query checking result. Each entry of the list is a list
        itself, containing the queried constraint elements.
    &#34;&#34;&#34;
    if self.query_checking_results is None:
        raise RuntimeError(&#34;You must run a query checking task before.&#34;)
    if len(queries) == 0 or len(queries) &gt; 3:
        raise RuntimeError(&#34;The list of queries has to contain at least one query and three queries as maximum&#34;)
    assignments = []
    for constraint in self.query_checking_results.keys():
        tmp_answer = []
        for query in queries:
            try:
                tmp_answer.append(self.query_checking_results[constraint][query])
            except KeyError:
                print(f&#34;{query} is not a valid query. Valid queries are template, activation, target.&#34;)
                sys.exit(1)
        assignments.append(tmp_answer)
    return assignments</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.get_binary_encoded_log"><code class="name flex">
<span>def <span class="ident">get_binary_encoded_log</span></span>(<span>self) >pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Return the one-hot encoding of the log.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>binary_encoded_log</code></dt>
<dd>the one-hot encoded log.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_binary_encoded_log(self) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Return the one-hot encoding of the log.

    Returns
    -------
    binary_encoded_log
        the one-hot encoded log.
    &#34;&#34;&#34;
    if self.log is None:
        raise RuntimeError(&#34;You must load a log before.&#34;)
    if self.frequent_item_sets is None:
        raise RuntimeError(&#34;You must run the item set extraction algorithm before.&#34;)

    return self.binary_encoded_log</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.get_frequent_item_sets"><code class="name flex">
<span>def <span class="ident">get_frequent_item_sets</span></span>(<span>self) >pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Return the set of extracted frequent item sets.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>frequent_item_sets</code></dt>
<dd>the set of extracted frequent item sets.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_frequent_item_sets(self) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Return the set of extracted frequent item sets.

    Returns
    -------
    frequent_item_sets
        the set of extracted frequent item sets.
    &#34;&#34;&#34;
    if self.log is None:
        raise RuntimeError(&#34;You must load a log before.&#34;)
    if self.frequent_item_sets is None:
        raise RuntimeError(&#34;You must run the item set extraction algorithm before.&#34;)

    return self.frequent_item_sets</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.get_log"><code class="name flex">
<span>def <span class="ident">get_log</span></span>(<span>self) >pm4py.objects.log.obj.EventLog</span>
</code></dt>
<dd>
<div class="desc"><p>Return the log previously fed in input.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>log</code></dt>
<dd>the input log.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_log(self) -&gt; pm4py.objects.log.obj.EventLog:
    &#34;&#34;&#34;
    Return the log previously fed in input.

    Returns
    -------
    log
        the input log.
    &#34;&#34;&#34;
    if self.log is None:
        raise RuntimeError(&#34;You must load a log before.&#34;)
    return self.log</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.get_log_alphabet_activities"><code class="name flex">
<span>def <span class="ident">get_log_alphabet_activities</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the set of activities that are in the log.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>activities</code></dt>
<dd>activity set.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_log_alphabet_activities(self):
    &#34;&#34;&#34;
    Return the set of activities that are in the log.

    Returns
    -------
    activities
        activity set.
    &#34;&#34;&#34;
    if self.log is None:
        raise RuntimeError(&#34;You must load a log before.&#34;)
    activities = set()
    for trace in self.log:
        for event in trace:
            activities.add(event[&#34;concept:name&#34;])
    return list(activities)</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.get_log_alphabet_payload"><code class="name flex">
<span>def <span class="ident">get_log_alphabet_payload</span></span>(<span>self) >set</span>
</code></dt>
<dd>
<div class="desc"><p>Return the set of resources that are in the log.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>resources</code></dt>
<dd>resource set.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_log_alphabet_payload(self) -&gt; set[str]:
    &#34;&#34;&#34;
    Return the set of resources that are in the log.

    Returns
    -------
    resources
        resource set.
    &#34;&#34;&#34;
    if self.log is None:
        raise RuntimeError(&#34;You must load a log before.&#34;)
    resources = set()
    for trace in self.log:
        for event in trace:
            resources.add(event[&#34;org:group&#34;])
    return resources</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.get_log_length"><code class="name flex">
<span>def <span class="ident">get_log_length</span></span>(<span>self) >int</span>
</code></dt>
<dd>
<div class="desc"><p>Return the number of traces contained in the log.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>log_length</code></dt>
<dd>the length of the log.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_log_length(self) -&gt; int:
    &#34;&#34;&#34;
    Return the number of traces contained in the log.

    Returns
    -------
    log_length
        the length of the log.
    &#34;&#34;&#34;
    if self.log is None:
        raise RuntimeError(&#34;You must load a log before.&#34;)
    return self.log_length</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.get_model_activities"><code class="name flex">
<span>def <span class="ident">get_model_activities</span></span>(<span>self) >list</span>
</code></dt>
<dd>
<div class="desc"><p>Return the activities contained in the DECLARE model.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>activities</code></dt>
<dd>list of activity names contained in the DECLARE model.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_model_activities(self) -&gt; list[str]:
    &#34;&#34;&#34;
    Return the activities contained in the DECLARE model.

    Returns
    -------
    activities
        list of activity names contained in the DECLARE model.
    &#34;&#34;&#34;
    if self.model is None:
        raise RuntimeError(&#34;You must load a DECLARE model before.&#34;)

    return self.model.activities</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.get_model_constraints"><code class="name flex">
<span>def <span class="ident">get_model_constraints</span></span>(<span>self) >list</span>
</code></dt>
<dd>
<div class="desc"><p>Return the constraints contained in the DECLARE model.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>activities</code></dt>
<dd>list of constraints contained in the DECLARE model.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_model_constraints(self) -&gt; list[str]:
    &#34;&#34;&#34;
    Return the constraints contained in the DECLARE model.

    Returns
    -------
    activities
        list of constraints contained in the DECLARE model.
    &#34;&#34;&#34;
    if self.model is None:
        raise RuntimeError(&#34;You must load a DECLARE model before.&#34;)

    return self.model.get_decl_model_constraints()</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.get_supported_templates"><code class="name flex">
<span>def <span class="ident">get_supported_templates</span></span>(<span>self) >tuple</span>
</code></dt>
<dd>
<div class="desc"><p>Return the DECLARE templates supported by Declare4Py.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>supported_templates</code></dt>
<dd>tuple of names of the supported DECLARE templates.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_supported_templates(self) -&gt; tuple[str, ...]:
    &#34;&#34;&#34;
    Return the DECLARE templates supported by Declare4Py.

    Returns
    -------
    supported_templates
        tuple of names of the supported DECLARE templates.
    &#34;&#34;&#34;
    return self.supported_templates</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.get_trace_keys"><code class="name flex">
<span>def <span class="ident">get_trace_keys</span></span>(<span>self) >list</span>
</code></dt>
<dd>
<div class="desc"><p>Return the name of each trace, along with the position in the log.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>trace_ids</code></dt>
<dd>list containing the position in the log and the name of the trace.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_trace_keys(self) -&gt; list[tuple[int, str]]:
    &#34;&#34;&#34;
    Return the name of each trace, along with the position in the log.

    Returns
    -------
    trace_ids
        list containing the position in the log and the name of the trace.
    &#34;&#34;&#34;
    if self.log is None:
        raise RuntimeError(&#34;You must load a log before.&#34;)
    trace_ids = []
    for trace_id, trace in enumerate(self.log):
        trace_ids.append((trace_id, trace.attributes[&#34;concept:name&#34;]))
    return trace_ids</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.log_encoding"><code class="name flex">
<span>def <span class="ident">log_encoding</span></span>(<span>self, dimension:str='act') >pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Return the log binary encoding, i.e. the one-hot encoding stating whether an attribute is contained
or not inside each trace of the log.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dimension</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>choose 'act' to perform the encoding over activity names, 'payload' over resources (default 'act').</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>binary_encoded_log</code></dt>
<dd>the one-hot encoding of the input log, made over activity names or resources depending on 'dimension' value.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_encoding(self, dimension: str = &#39;act&#39;) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Return the log binary encoding, i.e. the one-hot encoding stating whether an attribute is contained
    or not inside each trace of the log.

    Parameters
    ----------
    dimension : str, optional
        choose &#39;act&#39; to perform the encoding over activity names, &#39;payload&#39; over resources (default &#39;act&#39;).

    Returns
    -------
    binary_encoded_log
        the one-hot encoding of the input log, made over activity names or resources depending on &#39;dimension&#39; value.
    &#34;&#34;&#34;
    if self.log is None:
        raise RuntimeError(&#34;You must load a log before.&#34;)
    te = TransactionEncoder()
    if dimension == &#39;act&#39;:
        dataset = self.activities_log_projection()
    elif dimension == &#39;payload&#39;:
        dataset = self.resources_log_projection()
    else:
        raise RuntimeError(f&#34;{dimension} dimension not supported. Choose between &#39;act&#39; and &#39;payload&#39;&#34;)
    te_ary = te.fit(dataset).transform(dataset)
    self.binary_encoded_log = pd.DataFrame(te_ary, columns=te.columns_)
    return self.binary_encoded_log</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.parse_decl_model"><code class="name flex">
<span>def <span class="ident">parse_decl_model</span></span>(<span>self, model_path) >None</span>
</code></dt>
<dd>
<div class="desc"><p>Parse the input DECLARE model.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model_path</code></strong> :&ensp;<code>str</code></dt>
<dd>File path where the DECLARE model is stored.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_decl_model(self, model_path) -&gt; None:
    &#34;&#34;&#34;
    Parse the input DECLARE model.

    Parameters
    ----------
    model_path : str
        File path where the DECLARE model is stored.
    &#34;&#34;&#34;
    self.model = parse_decl_from_file(model_path)</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.parse_xes_log"><code class="name flex">
<span>def <span class="ident">parse_xes_log</span></span>(<span>self, log_path:str) >None</span>
</code></dt>
<dd>
<div class="desc"><p>Set the 'log' EventLog object and the 'log_length' integer by reading and parsing the log corresponding to
given log file path.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>log_path</code></strong> :&ensp;<code>str</code></dt>
<dd>File path where the log is stored.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_xes_log(self, log_path: str) -&gt; None:
    &#34;&#34;&#34;
    Set the &#39;log&#39; EventLog object and the &#39;log_length&#39; integer by reading and parsing the log corresponding to
    given log file path.

    Parameters
    ----------
    log_path : str
        File path where the log is stored.
    &#34;&#34;&#34;
    self.log = pm4py.read_xes(log_path)
    self.log_length = len(self.log)</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.print_conformance_results"><code class="name flex">
<span>def <span class="ident">print_conformance_results</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def print_conformance_results(self):
    if self.conformance_checking_results is None:
        raise RuntimeError(&#34;You must run conformance checking before!&#34;)

    for key, value in self.conformance_checking_results.items():
        print(&#39;Trace ID: &#39; + str(key[0]) + &#39; - &#34;&#39; + key[1] + &#39;&#34;&#39;)
        for item in value.items():
            print(&#39;\t&#39; + item[1].state + &#39;\ton &#39; + item[0])
        print()</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.query_checking"><code class="name flex">
<span>def <span class="ident">query_checking</span></span>(<span>self, consider_vacuity:bool, template_str:str=None, max_declare_cardinality:int=1, activation:str=None, target:str=None, act_cond:str=None, trg_cond:str=None, time_cond:str=None, min_support:float=1.0, return_first:bool=False) >dict</span>
</code></dt>
<dd>
<div class="desc"><p>Performs query checking for a (list of) template, activation activity and target activity. Optional
activation, target and time conditions can be specified.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>consider_vacuity</code></strong> :&ensp;<code>bool</code></dt>
<dd>True means that vacuously satisfied traces are considered as satisfied, violated otherwise.</dd>
<dt><strong><code>template_str</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>if specified, the query checking is restricted on this DECLARE template. If not, the query checking is
performed over the whole set of supported templates.</dd>
<dt><strong><code>max_declare_cardinality</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>the maximum cardinality that the algorithm checks for DECLARE templates supporting it (default 1).</dd>
<dt><strong><code>activation</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>if specified, the query checking is restricted on this activation activity. If not, the query checking
considers in turn each activity of the log as activation.</dd>
<dt><strong><code>target</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>if specified, the query checking is restricted on this target activity. If not, the query checking
considers in turn each activity of the log as target.</dd>
<dt><strong><code>act_cond</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>optional activation condition to evaluate. It has to be written by following the DECLARE standard format.</dd>
<dt><strong><code>trg_cond</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>optional target condition to evaluate. It has to be written by following the DECLARE standard format.</dd>
<dt><strong><code>time_cond</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>optional time condition to evaluate. It has to be written by following the DECLARE standard format.</dd>
<dt><strong><code>min_support</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>the minimum support that a constraint needs to have to be included in the result (default 1).</dd>
<dt><strong><code>return_first</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>if True, the algorithm returns only the first queried constraint that is above the minimum support. If
False, the algorithm returns all the constraints above the min. support (default False).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>query_checking_results</code></dt>
<dd>dictionary with keys the DECLARE constraints satisfying the assignments. The values are a structured
representations of these constraints.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def query_checking(self, consider_vacuity: bool,
                   template_str: str = None, max_declare_cardinality: int = 1,
                   activation: str = None, target: str = None,
                   act_cond: str = None, trg_cond: str = None, time_cond: str = None,
                   min_support: float = 1.0, return_first: bool = False) -&gt; dict[str: dict[str: str]]:
    &#34;&#34;&#34;
    Performs query checking for a (list of) template, activation activity and target activity. Optional
    activation, target and time conditions can be specified.

    Parameters
    ----------
    consider_vacuity : bool
        True means that vacuously satisfied traces are considered as satisfied, violated otherwise.

    template_str : str, optional
        if specified, the query checking is restricted on this DECLARE template. If not, the query checking is
        performed over the whole set of supported templates.

    max_declare_cardinality : int, optional
        the maximum cardinality that the algorithm checks for DECLARE templates supporting it (default 1).

    activation : str, optional
        if specified, the query checking is restricted on this activation activity. If not, the query checking
        considers in turn each activity of the log as activation.

    target : str, optional
        if specified, the query checking is restricted on this target activity. If not, the query checking
        considers in turn each activity of the log as target.

    act_cond : str, optional
        optional activation condition to evaluate. It has to be written by following the DECLARE standard format.

    trg_cond : str, optional
        optional target condition to evaluate. It has to be written by following the DECLARE standard format.

    time_cond : str, optional
        optional time condition to evaluate. It has to be written by following the DECLARE standard format.

    min_support : float, optional
        the minimum support that a constraint needs to have to be included in the result (default 1).

    return_first : bool, optional
        if True, the algorithm returns only the first queried constraint that is above the minimum support. If
        False, the algorithm returns all the constraints above the min. support (default False).

    Returns
    -------
    query_checking_results
        dictionary with keys the DECLARE constraints satisfying the assignments. The values are a structured
        representations of these constraints.
    &#34;&#34;&#34;
    print(&#34;Computing query checking ...&#34;)

    is_template_given = bool(template_str)
    is_activation_given = bool(activation)
    is_target_given = bool(target)
    if not act_cond:
        act_cond = &#34;&#34;
    if not trg_cond:
        trg_cond = &#34;&#34;
    if not time_cond:
        time_cond = &#34;&#34;

    if not is_template_given and not is_activation_given and not is_target_given:
        raise RuntimeError(&#34;You must set at least one parameter among (template, activation, target).&#34;)
    if is_template_given:
        template = Template.get_template_from_string(template_str)
        if template is None:
            raise RuntimeError(&#34;You must insert a supported DECLARE template.&#34;)
        if not template.is_binary and is_target_given:
            raise RuntimeError(&#34;You cannot specify a target activity for unary templates.&#34;)
    if not 0 &lt;= min_support &lt;= 1:
        raise RuntimeError(&#34;Min. support must be in range [0, 1].&#34;)
    if max_declare_cardinality &lt;= 0:
        raise RuntimeError(&#34;Cardinality must be greater than 0.&#34;)
    if self.log is None:
        raise RuntimeError(&#34;You must load a log before.&#34;)

    templates_to_check = list()
    if is_template_given:
        templates_to_check.append(template_str)
    else:
        templates_to_check += list(map(lambda t: t.templ_str, Template.get_binary_templates()))
        if not is_target_given:
            for template in Template.get_unary_templates():
                if template.supports_cardinality:
                    for card in range(max_declare_cardinality):
                        templates_to_check.append(template.templ_str + str(card+1))
                else:
                    templates_to_check.append(template.templ_str)

    activations_to_check = self.get_log_alphabet_activities() if activation is None else [activation]
    targets_to_check = self.get_log_alphabet_activities() if target is None else [target]
    activity_combos = tuple(filter(lambda c: c[0] != c[1], product(activations_to_check, targets_to_check)))

    self.query_checking_results = {}

    for template_str in templates_to_check:
        template_str, cardinality = re.search(r&#39;(^.+?)(\d*$)&#39;, template_str).groups()
        template = Template.get_template_from_string(template_str)

        constraint = {&#34;template&#34;: template}
        if cardinality:
            constraint[&#39;n&#39;] = int(cardinality)

        if template.is_binary:
            constraint[&#39;condition&#39;] = (act_cond, trg_cond, time_cond)
            for couple in activity_combos:
                constraint[&#39;attributes&#39;] = &#39;, &#39;.join(couple)

                constraint_str = query_constraint(self.log, constraint, consider_vacuity, min_support)
                if constraint_str:
                    res_value = {
                        &#34;template&#34;: template_str, &#34;activation&#34;: couple[0], &#34;target&#34;: couple[1],
                        &#34;act_cond&#34;: act_cond, &#34;trg_cond&#34;: trg_cond, &#34;time_cond&#34;: time_cond
                    }
                    self.query_checking_results[constraint_str] = res_value
                    if return_first:
                        return self.query_checking_results

        else:   # unary template
            constraint[&#39;condition&#39;] = (act_cond, time_cond)
            for activity in activations_to_check:
                constraint[&#39;attributes&#39;] = activity

                constraint_str = query_constraint(self.log, constraint, consider_vacuity, min_support)
                if constraint_str:
                    res_value = {
                        &#34;template&#34;: template_str, &#34;activation&#34;: activity,
                        &#34;act_cond&#34;: act_cond, &#34;time_cond&#34;: time_cond
                    }
                    self.query_checking_results[constraint_str] = res_value
                    if return_first:
                        return self.query_checking_results

    return self.query_checking_results</code></pre>
</details>
</dd>
<dt id="declare4py.declare4py.Declare4Py.resources_log_projection"><code class="name flex">
<span>def <span class="ident">resources_log_projection</span></span>(<span>self) >list</span>
</code></dt>
<dd>
<div class="desc"><p>Return for each trace a time-ordered list of the resources of the events.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>projection</code></dt>
<dd>nested lists, the outer one addresses traces while the inner one contains event activity names.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def resources_log_projection(self) -&gt; list[list[str]]:
    &#34;&#34;&#34;
    Return for each trace a time-ordered list of the resources of the events.

    Returns
    -------
    projection
        nested lists, the outer one addresses traces while the inner one contains event activity names.
    &#34;&#34;&#34;
    projection = []
    if self.log is None:
        raise RuntimeError(&#34;You must load a log before.&#34;)
    for trace in self.log:
        tmp_trace = []
        for event in trace:
            tmp_trace.append(event[&#34;org:group&#34;])
        projection.append(tmp_trace)
    return projection</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="declare4py" href="index.html">declare4py</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="declare4py.declare4py.Declare4Py" href="#declare4py.declare4py.Declare4Py">Declare4Py</a></code></h4>
<ul class="">
<li><code><a title="declare4py.declare4py.Declare4Py.activities_log_projection" href="#declare4py.declare4py.Declare4Py.activities_log_projection">activities_log_projection</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.compute_frequent_itemsets" href="#declare4py.declare4py.Declare4Py.compute_frequent_itemsets">compute_frequent_itemsets</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.conformance_checking" href="#declare4py.declare4py.Declare4Py.conformance_checking">conformance_checking</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.discovery" href="#declare4py.declare4py.Declare4Py.discovery">discovery</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.filter_discovery" href="#declare4py.declare4py.Declare4Py.filter_discovery">filter_discovery</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.filter_query_checking" href="#declare4py.declare4py.Declare4Py.filter_query_checking">filter_query_checking</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.get_binary_encoded_log" href="#declare4py.declare4py.Declare4Py.get_binary_encoded_log">get_binary_encoded_log</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.get_frequent_item_sets" href="#declare4py.declare4py.Declare4Py.get_frequent_item_sets">get_frequent_item_sets</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.get_log" href="#declare4py.declare4py.Declare4Py.get_log">get_log</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.get_log_alphabet_activities" href="#declare4py.declare4py.Declare4Py.get_log_alphabet_activities">get_log_alphabet_activities</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.get_log_alphabet_payload" href="#declare4py.declare4py.Declare4Py.get_log_alphabet_payload">get_log_alphabet_payload</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.get_log_length" href="#declare4py.declare4py.Declare4Py.get_log_length">get_log_length</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.get_model_activities" href="#declare4py.declare4py.Declare4Py.get_model_activities">get_model_activities</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.get_model_constraints" href="#declare4py.declare4py.Declare4Py.get_model_constraints">get_model_constraints</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.get_supported_templates" href="#declare4py.declare4py.Declare4Py.get_supported_templates">get_supported_templates</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.get_trace_keys" href="#declare4py.declare4py.Declare4Py.get_trace_keys">get_trace_keys</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.log_encoding" href="#declare4py.declare4py.Declare4Py.log_encoding">log_encoding</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.parse_decl_model" href="#declare4py.declare4py.Declare4Py.parse_decl_model">parse_decl_model</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.parse_xes_log" href="#declare4py.declare4py.Declare4Py.parse_xes_log">parse_xes_log</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.print_conformance_results" href="#declare4py.declare4py.Declare4Py.print_conformance_results">print_conformance_results</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.query_checking" href="#declare4py.declare4py.Declare4Py.query_checking">query_checking</a></code></li>
<li><code><a title="declare4py.declare4py.Declare4Py.resources_log_projection" href="#declare4py.declare4py.Declare4Py.resources_log_projection">resources_log_projection</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>